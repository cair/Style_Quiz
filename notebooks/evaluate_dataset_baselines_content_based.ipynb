{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaborg15\\Python_projects\\Vibrent_Dataset_Collection\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "print(os.getcwd())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "\n",
    "from resources.constants import *\n",
    "\n",
    "pictures_df = pd.read_csv(PICTURE_TRIPLETS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "outfits_df = pd.read_csv(OUTFITS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "user_triplets_df = pd.read_csv(USER_ACTIVITY_TRIPLETS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "# Ensure tags are lists\n",
    "outfits_df[\"tag_categories\"] = outfits_df[\"tag_categories\"].apply(eval)\n",
    "outfits_df[\"outfit_tags\"] = outfits_df[\"outfit_tags\"].apply(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.load_baseline_resources\n",
    "import pickle\n",
    "from resources.constants import EMBEDDING_MODEL_DICT_PICKLE_PATH\n",
    "# loaded_embeddings_dict = src.load_baseline_resources.load_embeddings_form_folder()\n",
    "# pickle.dump(loaded_embeddings_dict, open(EMBEDDING_MODEL_DICT_PICKLE_PATH, \"wb\"))\n",
    "\n",
    "# Loading embeddings is expensive, so we save them to a pickle file\n",
    "loaded_embeddings_dict = pickle.load(open(EMBEDDING_MODEL_DICT_PICKLE_PATH, \"rb\"))\n",
    "\n",
    "\n",
    "pictures_df[\"embeddings\"] = pictures_df[\"picture.id\"].map(loaded_embeddings_dict)\n",
    "outfit_pictures_df = pictures_df.groupby(\"outfit.id\").agg({\"picture.id\": list, \"embeddings\": list}).reset_index()\n",
    "outfits_df[\"embeddings\"] = outfits_df[\"id\"].map(outfit_pictures_df.set_index(\"outfit.id\")[\"embeddings\"])\n",
    "na_embedding_outfit_ids = outfits_df[outfits_df[\"embeddings\"].isna()][\"id\"]\n",
    "outfits_df = outfits_df.dropna(subset=[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce group to rental triplets\n",
    "id_group_dict = outfits_df[[\"id\", \"group\"]].to_dict(orient=\"records\")\n",
    "id_group_dict = {x[\"id\"]: x[\"group\"] for x in id_group_dict}\n",
    "user_triplets_df[\"group\"] = user_triplets_df[\"outfit.id\"].map(id_group_dict)\n",
    "# Remove triplets with no embeddings\n",
    "user_triplets_df = user_triplets_df[~user_triplets_df[\"outfit.id\"].isin(na_embedding_outfit_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No unique outfit found with groups ['group.8abe6af9eccc8b578c2ef59628f8b454'\n",
      " 'group.96f4cce22d4a236e0652c67fc9b18d12'\n",
      " 'group.8abe6af9eccc8b578c2ef59628f8b454'\n",
      " 'group.96f4cce22d4a236e0652c67fc9b18d12']\n"
     ]
    }
   ],
   "source": [
    "from src.prepare_train_test_splits import convert_user_orders_to_train_test_splits\n",
    "user_orders_df = user_triplets_df.groupby(\"customer.id\").agg({\"outfit.id\": list, \"group\":list, \"meta.validFrom\":list, \"derived.bookingTime\":list}).reset_index()\n",
    "user_orders_df[\"num_orders\"] = user_orders_df[\"outfit.id\"].apply(lambda x: len(x))\n",
    "user_orders_df = user_orders_df[user_orders_df[\"num_orders\"] > 1]\n",
    "\n",
    "user_splits_df, user_splits_unique_df = convert_user_orders_to_train_test_splits(user_orders_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f01b9f043f4300a53adf53e031e0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def build_tag_dict(tags, tag_categories):\n",
    "    tag_dict = {}\n",
    "    for tag, tag_category in zip(tags, tag_categories):\n",
    "        if tag_category not in tag_dict:\n",
    "            tag_dict[tag_category] = []\n",
    "        tag_dict[tag_category].append(tag)\n",
    "    return tag_dict\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "outfits_df[\"tag_dict\"] = outfits_df.progress_apply(lambda x: build_tag_dict(x[\"outfit_tags\"], x[\"tag_categories\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "all_tags = outfits_df[\"outfit_tags\"].values.tolist()\n",
    "mlb = MultiLabelBinarizer()\n",
    "one_hot_encoded = mlb.fit_transform(all_tags)\n",
    "outfits_df[\"one_hot_encoded\"] = [np.array(oh_list) for oh_list in one_hot_encoded.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>timeCreated</th>\n",
       "      <th>retailPrice</th>\n",
       "      <th>outfit_tags</th>\n",
       "      <th>tag_categories</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>tag_dict</th>\n",
       "      <th>one_hot_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outfit.fffdaa715c3646f8b1c0f04d549ff07e</td>\n",
       "      <td>Out of stock - Asymmetric Frilled Dress</td>\n",
       "      <td>This fun, short dress features and asymmetric ...</td>\n",
       "      <td>group.50a586c78eb7626e294ba3bd07d12c79</td>\n",
       "      <td>464</td>\n",
       "      <td>2017-12-30 11:28:01.000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>[Metallic, Synthetic, Cotton, Sandro, Dresses,...</td>\n",
       "      <td>[Details, Material, Material, Brand, Category,...</td>\n",
       "      <td>[[1.738, -0.0944, -0.0934, 0.1979, 0.2365, -0....</td>\n",
       "      <td>{'Details': ['Metallic'], 'Material': ['Synthe...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outfit.fffa1b9a3db6415d806f3c48f8ab58d9</td>\n",
       "      <td>Yellow Shell Mellomholmene Blouse</td>\n",
       "      <td>This beautiful blouse features an adjustable n...</td>\n",
       "      <td>group.61ad2fcabb3e9197e3836376e6b67f2c</td>\n",
       "      <td>112</td>\n",
       "      <td>2021-06-07 12:07:22.921</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>[Yellow, Cotton, Blouses, Everyday, M, Summer,...</td>\n",
       "      <td>[Color, Material, Category, Occasion, Size, Se...</td>\n",
       "      <td>[[-0.0843, -0.0567, -0.05966, -0.077, 1.166, -...</td>\n",
       "      <td>{'Color': ['Yellow'], 'Material': ['Cotton'], ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outfit.fff175b13ceb453f9928625491412ede</td>\n",
       "      <td>Kaula Dress Black</td>\n",
       "      <td>Kaula from Rodebjer is a fitted dress made in ...</td>\n",
       "      <td>group.37c2b59d63d3a9c2d58e07f532f71f7f</td>\n",
       "      <td>635</td>\n",
       "      <td>2023-06-05 09:17:59.004</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>[Synthetic, Multi Season, Rodebjer, Everyday, ...</td>\n",
       "      <td>[Material, Seasons, Brand, Occasion, Size, Cat...</td>\n",
       "      <td>[[1.27, -0.0494, -0.02313, -0.1021, 0.2625, 0....</td>\n",
       "      <td>{'Material': ['Synthetic'], 'Seasons': ['Multi...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outfit.ffef9d7c292a48b69076d2df2e32352f</td>\n",
       "      <td>For sale - Jarvis Blouse</td>\n",
       "      <td>This wrap blouse has mid length sleeves and a ...</td>\n",
       "      <td>group.dfcaa57546b0b7a5e9eb204449b6cc1c</td>\n",
       "      <td>745</td>\n",
       "      <td>2021-05-18 14:02:28.690</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>[Cotton, Multi Season, Floral, Wrap, XS, Style...</td>\n",
       "      <td>[Material, Seasons, Details, Fit, Size, Brand,...</td>\n",
       "      <td>[[-0.04453, -0.08777, -0.0676, -0.07196, 0.086...</td>\n",
       "      <td>{'Material': ['Cotton'], 'Seasons': ['Multi Se...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outfit.ffeef842238f4dbdabc6c730a75aa2bd</td>\n",
       "      <td>Black Amber Pants</td>\n",
       "      <td>Feel slack and nice dressed with this pant, ma...</td>\n",
       "      <td>group.ee297c977905eb21a123a4aea5fbb6d2</td>\n",
       "      <td>504</td>\n",
       "      <td>2021-07-16 14:02:30.643</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>[Winter, Cotton, L, Knitwear, Everyday, Fall, ...</td>\n",
       "      <td>[Seasons, Material, Size, Category, Occasion, ...</td>\n",
       "      <td>[[0.02425, -0.1558, -0.1343, -0.07513, -0.0170...</td>\n",
       "      <td>{'Seasons': ['Winter', 'Fall'], 'Material': ['...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15824</th>\n",
       "      <td>outfit.001bf665330140cf854dcfb1cbff6b5f</td>\n",
       "      <td>Out of stock - Harley Vintage White Midi Dress</td>\n",
       "      <td>This gorgeous dress is cut in the most flatter...</td>\n",
       "      <td>group.d91a2a6728833c8082dadf27b95488a9</td>\n",
       "      <td>140</td>\n",
       "      <td>2019-06-25 10:13:55.000</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>[Viscose, L, Midi, Dresses, White, Formal, Pia...</td>\n",
       "      <td>[Material, Size, Length, Category, Color, Occa...</td>\n",
       "      <td>[[-0.10986, -0.05212, -0.04785, -0.1338, 0.035...</td>\n",
       "      <td>{'Material': ['Viscose'], 'Size': ['L'], 'Leng...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15825</th>\n",
       "      <td>outfit.0018701ce6b049ebadc314d16623caa8</td>\n",
       "      <td>Vintage Burberry Trench Coat</td>\n",
       "      <td>You really can't go wrong with this Classic Tr...</td>\n",
       "      <td>group.6be510229d0f9faf5d19d52e7e2b2a95</td>\n",
       "      <td>58</td>\n",
       "      <td>2023-02-07 07:54:06.214</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>[Winter, Cotton, Midi, Everyday, Fall, Burberr...</td>\n",
       "      <td>[Seasons, Material, Length, Occasion, Seasons,...</td>\n",
       "      <td>[[0.9565, 0.6475, -0.0587, 0.704, 0.2399, 0.04...</td>\n",
       "      <td>{'Seasons': ['Winter', 'Fall'], 'Material': ['...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15826</th>\n",
       "      <td>outfit.0014a5c89b244077a3d7cffd4549718e</td>\n",
       "      <td>Mira Skirt Brown</td>\n",
       "      <td>The Mira Skirt in Brown from Stine Goya is an ...</td>\n",
       "      <td>group.668be5db7976aa2cb9213dd4c7f9b7fe</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-10-09 09:12:14.631</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>[Viscose, Midi, Skirts, Summer, Stine Goya, Ev...</td>\n",
       "      <td>[Material, Length, Category, Seasons, Brand, B...</td>\n",
       "      <td>[[-0.1237, -0.03632, -0.08435, -0.1036, 1.478,...</td>\n",
       "      <td>{'Material': ['Viscose'], 'Length': ['Midi'], ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15827</th>\n",
       "      <td>outfit.0013691ff35b440e9dcfe1748ec184c7</td>\n",
       "      <td>Oldina Parka Cotta</td>\n",
       "      <td>The Oldina Parka from Kari Traa is a women's p...</td>\n",
       "      <td>group.c82046bcba672c8ec9b21be4f844b402</td>\n",
       "      <td>552</td>\n",
       "      <td>2023-02-23 12:20:27.042</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>[Winter, Synthetic, Midi, Everyday, XS, Coats,...</td>\n",
       "      <td>[Seasons, Material, Length, Occasion, Size, Ca...</td>\n",
       "      <td>[[0.4219, 0.09644, -0.0454, 1.402, -0.08295, -...</td>\n",
       "      <td>{'Seasons': ['Winter'], 'Material': ['Syntheti...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15828</th>\n",
       "      <td>outfit.00004b4d01ca4ab0a70cf073ba74fefa</td>\n",
       "      <td>Yugen Black Cardigan</td>\n",
       "      <td>The FWSS Yugen Cardigan is a form-fitted cardi...</td>\n",
       "      <td>group.4002da292009a8bb0d403bbaf734184e</td>\n",
       "      <td>592</td>\n",
       "      <td>2022-03-01 10:58:12.456</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>[Wool, Winter, Everyday, Fall, M, Cardigans, B...</td>\n",
       "      <td>[Material, Seasons, Occasion, Seasons, Size, C...</td>\n",
       "      <td>[[0.733, -0.0905, -0.0949, 0.0719, 0.6807, -0....</td>\n",
       "      <td>{'Material': ['Wool'], 'Seasons': ['Winter', '...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15193 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            id  \\\n",
       "0      outfit.fffdaa715c3646f8b1c0f04d549ff07e   \n",
       "1      outfit.fffa1b9a3db6415d806f3c48f8ab58d9   \n",
       "2      outfit.fff175b13ceb453f9928625491412ede   \n",
       "3      outfit.ffef9d7c292a48b69076d2df2e32352f   \n",
       "4      outfit.ffeef842238f4dbdabc6c730a75aa2bd   \n",
       "...                                        ...   \n",
       "15824  outfit.001bf665330140cf854dcfb1cbff6b5f   \n",
       "15825  outfit.0018701ce6b049ebadc314d16623caa8   \n",
       "15826  outfit.0014a5c89b244077a3d7cffd4549718e   \n",
       "15827  outfit.0013691ff35b440e9dcfe1748ec184c7   \n",
       "15828  outfit.00004b4d01ca4ab0a70cf073ba74fefa   \n",
       "\n",
       "                                                 name  \\\n",
       "0             Out of stock - Asymmetric Frilled Dress   \n",
       "1                   Yellow Shell Mellomholmene Blouse   \n",
       "2                                   Kaula Dress Black   \n",
       "3                            For sale - Jarvis Blouse   \n",
       "4                                   Black Amber Pants   \n",
       "...                                               ...   \n",
       "15824  Out of stock - Harley Vintage White Midi Dress   \n",
       "15825                    Vintage Burberry Trench Coat   \n",
       "15826                                Mira Skirt Brown   \n",
       "15827                             Oldina Parka Cotta    \n",
       "15828                            Yugen Black Cardigan   \n",
       "\n",
       "                                             description  \\\n",
       "0      This fun, short dress features and asymmetric ...   \n",
       "1      This beautiful blouse features an adjustable n...   \n",
       "2      Kaula from Rodebjer is a fitted dress made in ...   \n",
       "3      This wrap blouse has mid length sleeves and a ...   \n",
       "4      Feel slack and nice dressed with this pant, ma...   \n",
       "...                                                  ...   \n",
       "15824  This gorgeous dress is cut in the most flatter...   \n",
       "15825  You really can't go wrong with this Classic Tr...   \n",
       "15826  The Mira Skirt in Brown from Stine Goya is an ...   \n",
       "15827  The Oldina Parka from Kari Traa is a women's p...   \n",
       "15828  The FWSS Yugen Cardigan is a form-fitted cardi...   \n",
       "\n",
       "                                        group  owner              timeCreated  \\\n",
       "0      group.50a586c78eb7626e294ba3bd07d12c79    464  2017-12-30 11:28:01.000   \n",
       "1      group.61ad2fcabb3e9197e3836376e6b67f2c    112  2021-06-07 12:07:22.921   \n",
       "2      group.37c2b59d63d3a9c2d58e07f532f71f7f    635  2023-06-05 09:17:59.004   \n",
       "3      group.dfcaa57546b0b7a5e9eb204449b6cc1c    745  2021-05-18 14:02:28.690   \n",
       "4      group.ee297c977905eb21a123a4aea5fbb6d2    504  2021-07-16 14:02:30.643   \n",
       "...                                       ...    ...                      ...   \n",
       "15824  group.d91a2a6728833c8082dadf27b95488a9    140  2019-06-25 10:13:55.000   \n",
       "15825  group.6be510229d0f9faf5d19d52e7e2b2a95     58  2023-02-07 07:54:06.214   \n",
       "15826  group.668be5db7976aa2cb9213dd4c7f9b7fe      4  2023-10-09 09:12:14.631   \n",
       "15827  group.c82046bcba672c8ec9b21be4f844b402    552  2023-02-23 12:20:27.042   \n",
       "15828  group.4002da292009a8bb0d403bbaf734184e    592  2022-03-01 10:58:12.456   \n",
       "\n",
       "       retailPrice                                        outfit_tags  \\\n",
       "0           4000.0  [Metallic, Synthetic, Cotton, Sandro, Dresses,...   \n",
       "1           1300.0  [Yellow, Cotton, Blouses, Everyday, M, Summer,...   \n",
       "2           3100.0  [Synthetic, Multi Season, Rodebjer, Everyday, ...   \n",
       "3           1500.0  [Cotton, Multi Season, Floral, Wrap, XS, Style...   \n",
       "4           1200.0  [Winter, Cotton, L, Knitwear, Everyday, Fall, ...   \n",
       "...            ...                                                ...   \n",
       "15824       3800.0  [Viscose, L, Midi, Dresses, White, Formal, Pia...   \n",
       "15825      22000.0  [Winter, Cotton, Midi, Everyday, Fall, Burberr...   \n",
       "15826       1500.0  [Viscose, Midi, Skirts, Summer, Stine Goya, Ev...   \n",
       "15827       3500.0  [Winter, Synthetic, Midi, Everyday, XS, Coats,...   \n",
       "15828       1900.0  [Wool, Winter, Everyday, Fall, M, Cardigans, B...   \n",
       "\n",
       "                                          tag_categories  \\\n",
       "0      [Details, Material, Material, Brand, Category,...   \n",
       "1      [Color, Material, Category, Occasion, Size, Se...   \n",
       "2      [Material, Seasons, Brand, Occasion, Size, Cat...   \n",
       "3      [Material, Seasons, Details, Fit, Size, Brand,...   \n",
       "4      [Seasons, Material, Size, Category, Occasion, ...   \n",
       "...                                                  ...   \n",
       "15824  [Material, Size, Length, Category, Color, Occa...   \n",
       "15825  [Seasons, Material, Length, Occasion, Seasons,...   \n",
       "15826  [Material, Length, Category, Seasons, Brand, B...   \n",
       "15827  [Seasons, Material, Length, Occasion, Size, Ca...   \n",
       "15828  [Material, Seasons, Occasion, Seasons, Size, C...   \n",
       "\n",
       "                                              embeddings  \\\n",
       "0      [[1.738, -0.0944, -0.0934, 0.1979, 0.2365, -0....   \n",
       "1      [[-0.0843, -0.0567, -0.05966, -0.077, 1.166, -...   \n",
       "2      [[1.27, -0.0494, -0.02313, -0.1021, 0.2625, 0....   \n",
       "3      [[-0.04453, -0.08777, -0.0676, -0.07196, 0.086...   \n",
       "4      [[0.02425, -0.1558, -0.1343, -0.07513, -0.0170...   \n",
       "...                                                  ...   \n",
       "15824  [[-0.10986, -0.05212, -0.04785, -0.1338, 0.035...   \n",
       "15825  [[0.9565, 0.6475, -0.0587, 0.704, 0.2399, 0.04...   \n",
       "15826  [[-0.1237, -0.03632, -0.08435, -0.1036, 1.478,...   \n",
       "15827  [[0.4219, 0.09644, -0.0454, 1.402, -0.08295, -...   \n",
       "15828  [[0.733, -0.0905, -0.0949, 0.0719, 0.6807, -0....   \n",
       "\n",
       "                                                tag_dict  \\\n",
       "0      {'Details': ['Metallic'], 'Material': ['Synthe...   \n",
       "1      {'Color': ['Yellow'], 'Material': ['Cotton'], ...   \n",
       "2      {'Material': ['Synthetic'], 'Seasons': ['Multi...   \n",
       "3      {'Material': ['Cotton'], 'Seasons': ['Multi Se...   \n",
       "4      {'Seasons': ['Winter', 'Fall'], 'Material': ['...   \n",
       "...                                                  ...   \n",
       "15824  {'Material': ['Viscose'], 'Size': ['L'], 'Leng...   \n",
       "15825  {'Seasons': ['Winter', 'Fall'], 'Material': ['...   \n",
       "15826  {'Material': ['Viscose'], 'Length': ['Midi'], ...   \n",
       "15827  {'Seasons': ['Winter'], 'Material': ['Syntheti...   \n",
       "15828  {'Material': ['Wool'], 'Seasons': ['Winter', '...   \n",
       "\n",
       "                                         one_hot_encoded  \n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "15824  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "15825  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "15826  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "15827  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "15828  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[15193 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataframe (example)\n",
    "# outfits_df = pd.read_csv(\"path_to_your_dataframe.csv\")\n",
    "\n",
    "# Assuming your dataframe has the following columns:\n",
    "# \"one_hot_encoded\" and \"mean_embeddings\"\n",
    "# Convert them to numpy arrays\n",
    "def get_mean_embedding(embeddings):\n",
    "    embeddings = np.array(embeddings)\n",
    "    mean_embedding = np.mean(embeddings, axis=0)\n",
    "    return mean_embedding\n",
    "\n",
    "def concatenate_embeddings(oh_embeddings, image_embeddings, oh_weighting):\n",
    "    oh_embeddings = np.array(oh_embeddings) * oh_weighting\n",
    "    return np.concatenate((oh_embeddings, image_embeddings))\n",
    "\n",
    "outfits_df[\"mean_embeddings\"] = outfits_df[\"embeddings\"].apply(lambda x: get_mean_embedding(x))\n",
    "#one_hot_encoded = np.array(outfits_df[\"one_hot_encoded\"].tolist())\n",
    "#mean_embeddings = np.array(outfits_df[\"mean_embeddings\"].tolist())\n",
    "\n",
    "outfits_df[\"concatenated_embeddings\"] = outfits_df.apply(lambda x: concatenate_embeddings(x[\"one_hot_encoded\"], x[\"mean_embeddings\"], oh_weighting=4), axis=1)\n",
    "input_embeddings = outfits_df[\"concatenated_embeddings\"]#np.concatenate((one_hot_encoded, mean_embeddings), axis=1)\n",
    "input_embeddings = torch.tensor(input_embeddings.tolist(), dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a5314af7984ecc96c4527a14c31f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.1251\n",
      "Epoch [2/3], Loss: 0.1069\n",
      "Epoch [3/3], Loss: 0.1113\n"
     ]
    }
   ],
   "source": [
    "# Define the autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()  # Assuming the input is normalized between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "# Define the dimensions\n",
    "input_dim = input_embeddings.shape[1]\n",
    "hidden_dim = 2048  # You can adjust this as needed\n",
    "latent_dim = 512   # You can adjust this as needed\n",
    "\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = Autoencoder(input_dim, hidden_dim, latent_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    permutation = torch.randperm(input_embeddings.size()[0])\n",
    "    \n",
    "    for i in range(0, input_embeddings.size()[0], batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_inputs = input_embeddings[indices]\n",
    "\n",
    "        # Forward pass\n",
    "        encoded, decoded = model(batch_inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(decoded, batch_inputs)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Save the model\n",
    "#torch.save(model.state_dict(), 'autoencoder_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15193, 512)\n"
     ]
    }
   ],
   "source": [
    "def get_outfit_embeddings(outfits_df, model):\n",
    "    one_hot_encoded = np.array(outfits_df[\"one_hot_encoded\"].tolist())\n",
    "    mean_embeddings = np.array(outfits_df[\"mean_embeddings\"].tolist())\n",
    "    input_embeddings = np.concatenate((one_hot_encoded, mean_embeddings), axis=1)\n",
    "    input_embeddings = torch.tensor(input_embeddings, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        encoded, decoded = model(input_embeddings)\n",
    "    return encoded\n",
    "\n",
    "outfit_embeddings = get_outfit_embeddings(outfits_df, model)\n",
    "outfits_df[\"outfit_embeddings\"] = [x.numpy() for x in outfit_embeddings]\n",
    "print(np.stack(outfits_df[\"outfit_embeddings\"].values).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "NUM_ITEMS = 100\n",
    "\n",
    "def find_rental_history_embeddings(outfit_ids, outfit_to_embedding_dict):\n",
    "    return [outfit_to_embedding_dict[outfit_id] for outfit_id in outfit_ids]\n",
    "\n",
    "def get_mean_embedding(embeddings):\n",
    "    embeddings = np.array(embeddings)\n",
    "    mean_embedding = np.mean(embeddings, axis=0)\n",
    "    return mean_embedding\n",
    "\n",
    "def get_nearest_neighbors_batch(embeddings, nn, num_items, index_to_id):\n",
    "    distances, indices = nn.kneighbors(embeddings, n_neighbors=num_items+1)\n",
    "    ids = [[index_to_id[i] for i in idx[1:]] for idx in indices]\n",
    "    distances = [dist[1:] for dist in distances]\n",
    "    return ids, distances\n",
    "\n",
    "\n",
    "def predict_nearest_neighbors(df, outfits_df, embeddings_column=\"embeddings\", subset_length=-1):\n",
    "    outfit_to_embedding_dict = outfits_df.set_index(\"id\")[embeddings_column].to_dict()\n",
    "    index_to_outfit_dict = {i: outfit_id for i, outfit_id in enumerate(outfits_df[\"id\"].values)}\n",
    "    group_to_embedding_dict = outfits_df.set_index(\"group\")[embeddings_column].to_dict()\n",
    "    index_to_group_dict = {i: group for i, group in enumerate(outfits_df[\"group\"].values)}\n",
    "\n",
    "    df[\"train_id_embeddings\"] = df[\"train_outfit_ids\"].apply(lambda x: find_rental_history_embeddings(x, outfit_to_embedding_dict))\n",
    "    df[\"train_group_embeddings\"] = df[\"train_group\"].apply(lambda x: find_rental_history_embeddings(x, group_to_embedding_dict))\n",
    "\n",
    "    df[\"rental_history_id_embedding\"] = df[\"train_id_embeddings\"].apply(lambda x: get_mean_embedding(x))\n",
    "    df[\"rental_history_group_embedding\"] = df[\"train_group_embeddings\"].apply(lambda x: get_mean_embedding(x))\n",
    "\n",
    "    nearest_neighbors = NearestNeighbors(n_neighbors=NUM_ITEMS+1, metric=\"cosine\")\n",
    "    embeddings = np.stack(outfits_df[embeddings_column].values)\n",
    "    nearest_neighbors.fit(embeddings)\n",
    "\n",
    "    id_embeddings = np.stack(df[\"rental_history_id_embedding\"].values)\n",
    "    group_embeddings = np.stack(df[\"rental_history_group_embedding\"].values)\n",
    "\n",
    "    id_predictions, id_distances = get_nearest_neighbors_batch(id_embeddings, nearest_neighbors, NUM_ITEMS, index_to_outfit_dict)\n",
    "    group_predictions, group_distances = get_nearest_neighbors_batch(group_embeddings, nearest_neighbors, NUM_ITEMS, index_to_group_dict)\n",
    "\n",
    "    df[\"id_prediction\"], df[\"id_prediction_distances\"] = id_predictions, id_distances\n",
    "    df[\"group_prediction\"], df[\"group_prediction_distances\"] = group_predictions, group_distances\n",
    "    \n",
    "    return df\n",
    "\n",
    "def predict_nearest_neighbors_images(df, outfits_df, embeddings_column=\"embeddings\", subset_length=-1):\n",
    "    outfits_df[\"mean_embeddings\"] = outfits_df[embeddings_column].apply(lambda x: get_mean_embedding(x))\n",
    "\n",
    "    return predict_nearest_neighbors(df, outfits_df, embeddings_column=\"mean_embeddings\", subset_length=subset_length)\n",
    "\n",
    "# Apply to dataframes\n",
    "tqdm.pandas()\n",
    "\n",
    "# Tag based predictions\n",
    "# user_splits_df = predict_nearest_neighbors(user_splits_df, outfits_df, embeddings_column=\"one_hot_encoded\", subset_length=-1)\n",
    "# user_splits_unique_df = predict_nearest_neighbors(user_splits_unique_df, outfits_df, embeddings_column=\"one_hot_encoded\", subset_length=-1)\n",
    "\n",
    "# Image based predictions\n",
    "# user_splits_df = predict_nearest_neighbors_images(user_splits_df, outfits_df, embeddings_column=\"embeddings\", subset_length=-1)\n",
    "# user_splits_unique_df = predict_nearest_neighbors_images(user_splits_unique_df, outfits_df, embeddings_column=\"embeddings\", subset_length=-1)\n",
    "\n",
    "# Combined predictions\n",
    "# user_splits_df = predict_nearest_neighbors(user_splits_df, outfits_df, embeddings_column=\"outfit_embeddings\", subset_length=-1)\n",
    "# user_splits_unique_df = predict_nearest_neighbors(user_splits_unique_df, outfits_df, embeddings_column=\"outfit_embeddings\", subset_length=-1)\n",
    "\n",
    "# Concat predictions\n",
    "user_splits_df = predict_nearest_neighbors(user_splits_df, outfits_df, embeddings_column=\"concatenated_embeddings\", subset_length=-1)\n",
    "user_splits_unique_df = predict_nearest_neighbors(user_splits_unique_df, outfits_df, embeddings_column=\"concatenated_embeddings\", subset_length=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.071300\n",
       "id_hit_rate_at_10        0.018502\n",
       "group_hit_rate_at_100    0.073556\n",
       "group_hit_rate_at_10     0.019856\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.081716\n",
       "id_hit_rate_at_10        0.021670\n",
       "group_hit_rate_at_100    0.079910\n",
       "group_hit_rate_at_10     0.023928\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def evaluate_hit_rate_at_n(test_id, predicted_ids, n=10):\n",
    "    if predicted_ids is np.nan:\n",
    "        print(f\"None prediction for {test_id}!\")\n",
    "        return 0\n",
    "    predicted_ids = predicted_ids[:n]\n",
    "    if test_id in predicted_ids:\n",
    "        #print(f\"Hit at {n} for {test_id} in {predicted_ids}\")\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "HIT_RATE_COLUMNS = [\"id_hit_rate_at_100\", \"id_hit_rate_at_10\", \"group_hit_rate_at_100\", \"group_hit_rate_at_10\"]\n",
    "def evaluate_df_hit_rate_at_n(df, n=10):\n",
    "    df[\"id_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"id_prediction\"], n=100), axis=1)\n",
    "    df[\"id_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"id_prediction\"], n=10), axis=1)\n",
    "    df[\"group_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_prediction\"], n=100), axis=1)\n",
    "    df[\"group_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_prediction\"], n=10), axis=1)\n",
    "    display(df[HIT_RATE_COLUMNS].mean())\n",
    "    return df\n",
    "\n",
    "\n",
    "user_splits_df = evaluate_df_hit_rate_at_n(user_splits_df, n=10)\n",
    "user_splits_unique_df = evaluate_df_hit_rate_at_n(user_splits_unique_df, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag + image embed Ind: & 0.0212 & 0.0799 & 0.0230 & 0.0944 \\\\\n",
      "Tag + image embed Groups: & 0.0208 & 0.0799 & 0.0244 & 0.0889 \\\\\\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyperclip\n",
    "\n",
    "def format_dicts_into_latex(all_dict, ind_dict, precision=4, run_name=\"Random\"):\n",
    "    first_row = f\"{run_name} Ind: & {all_dict['id_hit_rate_at_10']:.{precision}f} & {all_dict['id_hit_rate_at_100']:.{precision}f} & {ind_dict['id_hit_rate_at_10']:.{precision}f} & {ind_dict['id_hit_rate_at_100']:.{precision}f} \\\\\\\\\"\n",
    "    second_row = f\"{run_name} Groups: & {all_dict['group_hit_rate_at_10']:.{precision}f} & {all_dict['group_hit_rate_at_100']:.{precision}f} & {ind_dict['group_hit_rate_at_10']:.{precision}f} & {ind_dict['group_hit_rate_at_100']:.{precision}f} \\\\\\\\\\\\hline\"\n",
    "    full_string = first_row + \"\\n\" + second_row + \"\\n\"\n",
    "    print(full_string)\n",
    "    pyperclip.copy(full_string)\n",
    "\n",
    "all_dict = {column: user_splits_df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "ind_dict = {column: user_splits_unique_df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "\n",
    "format_dicts_into_latex(all_dict, ind_dict, precision=4, run_name=\"Tag + image embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_outfit_category(tag_categories, tags, category):\n",
    "    tag_categories, tags = np.array(tag_categories), np.array(tags)\n",
    "    category_indexes = np.where(tag_categories == category)[0]\n",
    "    if len(category_indexes) == 0:\n",
    "        return \"\"\n",
    "    cat_tags = tags[category_indexes]\n",
    "    output = str(cat_tags[0])\n",
    "    return output\n",
    "\n",
    "outfits_df[\"size\"] = outfits_df.apply(lambda x: get_outfit_category(x[\"tag_categories\"], x[\"outfit_tags\"], \"Size\"), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfits_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

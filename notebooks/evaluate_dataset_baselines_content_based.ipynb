{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaborg15\\Python_projects\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resources/data/dataset/picture_triplets.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mresources\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 14\u001b[0m pictures_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPICTURE_TRIPLETS_CSV_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCSV_SEPARATOR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m outfits_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(OUTFITS_CSV_PATH, sep\u001b[38;5;241m=\u001b[39mCSV_SEPARATOR)\n\u001b[0;32m     16\u001b[0m user_triplets_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(USER_ACTIVITY_TRIPLETS_CSV_PATH, sep\u001b[38;5;241m=\u001b[39mCSV_SEPARATOR)\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1012\u001b[0m     dialect,\n\u001b[0;32m   1013\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resources/data/dataset/picture_triplets.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "print(os.getcwd())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "\n",
    "from resources.constants import *\n",
    "\n",
    "pictures_df = pd.read_csv(PICTURE_TRIPLETS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "outfits_df = pd.read_csv(OUTFITS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "user_triplets_df = pd.read_csv(USER_ACTIVITY_TRIPLETS_CSV_PATH, sep=CSV_SEPARATOR)\n",
    "# Ensure tags are lists\n",
    "outfits_df[\"tag_categories\"] = outfits_df[\"tag_categories\"].apply(eval)\n",
    "outfits_df[\"outfit_tags\"] = outfits_df[\"outfit_tags\"].apply(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.load_baseline_resources\n",
    "import pickle\n",
    "from resources.constants import EMBEDDING_MODEL_DICT_PICKLE_PATH\n",
    "# loaded_embeddings_dict = src.load_baseline_resources.load_embeddings_form_folder()\n",
    "# pickle.dump(loaded_embeddings_dict, open(EMBEDDING_MODEL_DICT_PICKLE_PATH, \"wb\"))\n",
    "\n",
    "loaded_embeddings_dict = pickle.load(open(EMBEDDING_MODEL_DICT_PICKLE_PATH, \"rb\"))\n",
    "pictures_df[\"embeddings\"] = pictures_df[\"picture.id\"].map(loaded_embeddings_dict)\n",
    "outfit_pictures_df = pictures_df.groupby(\"outfit.id\").agg({\"picture.id\": list, \"embeddings\": list}).reset_index()\n",
    "outfits_df[\"embeddings\"] = outfits_df[\"id\"].map(outfit_pictures_df.set_index(\"outfit.id\")[\"embeddings\"])\n",
    "na_embedding_outfit_ids = outfits_df[outfits_df[\"embeddings\"].isna()][\"id\"]\n",
    "outfits_df = outfits_df.dropna(subset=[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce group to rental triplets\n",
    "id_group_dict = outfits_df[[\"id\", \"group\"]].to_dict(orient=\"records\")\n",
    "id_group_dict = {x[\"id\"]: x[\"group\"] for x in id_group_dict}\n",
    "user_triplets_df[\"group\"] = user_triplets_df[\"outfit.id\"].map(id_group_dict)\n",
    "# Remove triplets with no embeddings\n",
    "user_triplets_df = user_triplets_df[~user_triplets_df[\"outfit.id\"].isin(na_embedding_outfit_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2216.000000\n",
       "mean       28.939982\n",
       "std        41.905801\n",
       "min         2.000000\n",
       "25%         5.000000\n",
       "50%        13.000000\n",
       "75%        35.000000\n",
       "max       356.000000\n",
       "Name: num_orders, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_orders_df = user_triplets_df.groupby(\"customer.id\").agg({\"outfit.id\": list, \"group\":list, \"meta.validFrom\":list, \"derived.bookingTime\":list}).reset_index()\n",
    "user_orders_df[\"num_orders\"] = user_orders_df[\"outfit.id\"].apply(lambda x: len(x))\n",
    "user_orders_df = user_orders_df[user_orders_df[\"num_orders\"] > 1]\n",
    "user_orders_df[\"num_orders\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No unique outfit found with groups ['group.8abe6af9eccc8b578c2ef59628f8b454'\n",
      " 'group.96f4cce22d4a236e0652c67fc9b18d12'\n",
      " 'group.8abe6af9eccc8b578c2ef59628f8b454'\n",
      " 'group.96f4cce22d4a236e0652c67fc9b18d12']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def leave_one_out_split(outfit_ids, groups, derived_booking_times):\n",
    "    outfit_ids = np.array(outfit_ids)\n",
    "    groups = np.array(groups)\n",
    "    derived_booking_times = np.array(derived_booking_times)\n",
    "    sorted_indices = np.argsort(derived_booking_times)\n",
    "    return outfit_ids[sorted_indices[:-1]], outfit_ids[sorted_indices[-1]], groups[sorted_indices[:-1]], groups[sorted_indices[-1]], derived_booking_times[sorted_indices[:-1]], derived_booking_times[sorted_indices[-1]]\n",
    "\n",
    "def leave_one_out_split_unique(outfit_ids, groups, derived_booking_times):\n",
    "    outfit_ids = np.array(outfit_ids)\n",
    "    groups = np.array(groups)\n",
    "    derived_booking_times = np.array(derived_booking_times)\n",
    "    \n",
    "    sorted_indices = np.argsort(derived_booking_times)\n",
    "    sorted_outfit_ids = outfit_ids[sorted_indices]\n",
    "    sorted_groups = groups[sorted_indices]\n",
    "    sorted_booking_times = derived_booking_times[sorted_indices]\n",
    "    \n",
    "    unique_groups, counts = np.unique(sorted_groups, return_counts=True)\n",
    "    \n",
    "    single_count_indices = np.where(counts == 1)[0]\n",
    "    if len(single_count_indices) == 0:\n",
    "        print(f\"No unique outfit found with groups {groups}\")\n",
    "        return None\n",
    "    \n",
    "    unique_group = unique_groups[single_count_indices[0]]\n",
    "    unique_group_index = np.where(sorted_groups == unique_group)[0][0]\n",
    "    remaining_indices = np.arange(len(sorted_groups)) != unique_group_index\n",
    "    \n",
    "    return (\n",
    "        sorted_outfit_ids[remaining_indices], sorted_outfit_ids[unique_group_index],\n",
    "        sorted_groups[remaining_indices], sorted_groups[unique_group_index],\n",
    "        sorted_booking_times[remaining_indices], sorted_booking_times[unique_group_index]\n",
    "    )\n",
    "\n",
    "\n",
    "user_splits = user_orders_df.apply(lambda x: leave_one_out_split(x[\"outfit.id\"], x[\"group\"], x[\"derived.bookingTime\"]), axis=1)\n",
    "user_splits_df = pd.DataFrame(user_splits.tolist(), columns=[\"train_outfit_ids\", \"test_outfit_id\", \"train_group\", \"test_group\", \"train_booking_times\", \"test_booking_time\"])\n",
    "user_splits_unique = user_orders_df.apply(lambda x: leave_one_out_split_unique(x[\"outfit.id\"], x[\"group\"], x[\"derived.bookingTime\"]), axis=1)\n",
    "user_splits_unique_df = pd.DataFrame(user_splits_unique.tolist(), columns=[\"train_outfit_ids\", \"test_outfit_id\", \"train_group\", \"test_group\", \"train_booking_times\", \"test_booking_time\"])\n",
    "user_splits_unique_df = user_splits_unique_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd57ef2e615b467bbc10d39e4be7b666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     90\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas()\n\u001b[1;32m---> 91\u001b[0m user_splits_df \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_nearest_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_splits_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfits_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m user_splits_unique_df \u001b[38;5;241m=\u001b[39m predict_nearest_neighbors(user_splits_unique_df, outfits_df, subset_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 83\u001b[0m, in \u001b[0;36mpredict_nearest_neighbors\u001b[1;34m(df, outfits_df, subset_length)\u001b[0m\n\u001b[0;32m     80\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(outfits_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     81\u001b[0m nearest_neighbors\u001b[38;5;241m.\u001b[39mfit(embeddings)\n\u001b[1;32m---> 83\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msubset_length\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_nearest_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrental_history_id_embedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnearest_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_ITEMS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_to_outfit_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m], df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_prediction_distances\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m]), predictions\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     85\u001b[0m group_predictions \u001b[38;5;241m=\u001b[39m df[:subset_length]\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_nearest_neighbors(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrental_history_group_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m], nearest_neighbors, NUM_ITEMS, index_to_group_dict), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\tqdm\\std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\pandas\\core\\frame.py:10347\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10335\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10337\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10345\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10346\u001b[0m )\n\u001b[1;32m> 10347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\tqdm\\std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[14], line 83\u001b[0m, in \u001b[0;36mpredict_nearest_neighbors.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     80\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(outfits_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     81\u001b[0m nearest_neighbors\u001b[38;5;241m.\u001b[39mfit(embeddings)\n\u001b[1;32m---> 83\u001b[0m predictions \u001b[38;5;241m=\u001b[39m df[:subset_length]\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mget_nearest_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrental_history_id_embedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnearest_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_ITEMS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_to_outfit_dict\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     84\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m], df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_prediction_distances\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m]), predictions\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     85\u001b[0m group_predictions \u001b[38;5;241m=\u001b[39m df[:subset_length]\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_nearest_neighbors(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrental_history_group_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m], nearest_neighbors, NUM_ITEMS, index_to_group_dict), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 55\u001b[0m, in \u001b[0;36mget_nearest_neighbors\u001b[1;34m(init_embeddings, nn, num_items, index_to_id)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_nearest_neighbors\u001b[39m(init_embeddings, nn, num_items, index_to_id):\n\u001b[1;32m---> 55\u001b[0m     distances, indices \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minit_embeddings\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     ids \u001b[38;5;241m=\u001b[39m [index_to_id[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m:]]\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ids[\u001b[38;5;241m1\u001b[39m:], distances[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\neighbors\\_base.py:887\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    885\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 887\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2144\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2143\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 2144\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   2145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   2146\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2147\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   2148\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   2149\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   2150\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2331\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2328\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2329\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1871\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1868\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1873\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1874\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1108\u001b[0m, in \u001b[0;36mcosine_distances\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m \n\u001b[0;32m   1075\u001b[0m \u001b[38;5;124;03mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;124;03m       [0.42..., 0.18...]])\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[1;32m-> 1108\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1109\u001b[0m S \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1110\u001b[0m S \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1657\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1614\u001b[0m \n\u001b[0;32m   1615\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1653\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1657\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1659\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:172\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    165\u001b[0m         X,\n\u001b[0;32m    166\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\utils\\validation.py:951\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    949\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 951\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    955\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaborg15\\AppData\\Local\\anaconda3\\envs\\baseline-env\\lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import src.rs_methods\n",
    "from tqdm.notebook import tqdm\n",
    "NUM_ITEMS = 100\n",
    "\n",
    "# Image Based Nearest Neighbors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def find_rental_history_embeddings(outfit_ids, outfit_to_embedding_dict):\n",
    "    return [outfit_to_embedding_dict[outfit_id] for outfit_id in outfit_ids]\n",
    "\n",
    "def get_mean_embedding(embeddings):\n",
    "    embeddings = np.array(embeddings)\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "def get_nearest_neighbors(init_embeddings, nn, num_items, index_to_id):\n",
    "    distances, indices = nn.kneighbors([init_embeddings], n_neighbors=num_items+1)\n",
    "    ids = [index_to_id[i] for i in indices[0][1:]]\n",
    "    return ids[1:], distances[0][1:]\n",
    "\n",
    "def predict_nearest_neighbors(df, outfits_df, subset_length=-1):\n",
    "    outfits_df[\"mean_embeddings\"] = outfits_df[\"embeddings\"].apply(lambda x: get_mean_embedding(x))\n",
    "    outfit_to_embedding_dict = outfits_df.set_index(\"id\")[\"mean_embeddings\"].to_dict()\n",
    "    index_to_outfit_dict = {i: outfit_id for i, outfit_id in enumerate(outfits_df[\"id\"].values)}\n",
    "    group_to_embedding_dict = outfits_df.set_index(\"group\")[\"mean_embeddings\"].to_dict()\n",
    "    index_to_group_dict = {i: group for i, group in enumerate(outfits_df[\"group\"].values)}\n",
    "\n",
    "    df[\"train_id_embeddings\"] = df[\"train_outfit_ids\"].apply(lambda x: find_rental_history_embeddings(x, outfit_to_embedding_dict))\n",
    "    df[\"train_group_embeddings\"] = df[\"train_group\"].apply(lambda x: find_rental_history_embeddings(x, group_to_embedding_dict))\n",
    "\n",
    "    df[\"rental_history_id_embedding\"] = df[\"train_id_embeddings\"].apply(lambda x: get_mean_embedding(x))\n",
    "    df[\"rental_history_group_embedding\"] = df[\"train_group_embeddings\"].apply(lambda x: get_mean_embedding(x))\n",
    "\n",
    "\n",
    "    nearest_neighbors = NearestNeighbors(n_neighbors=NUM_ITEMS, metric=\"cosine\")\n",
    "    embeddings = np.stack(outfits_df[\"mean_embeddings\"].values)\n",
    "    nearest_neighbors.fit(embeddings)\n",
    "\n",
    "    predictions = df[:subset_length].progress_apply(lambda x: get_nearest_neighbors(x[\"rental_history_id_embedding\"], nearest_neighbors, NUM_ITEMS, index_to_outfit_dict), axis=1)\n",
    "    df[\"id_prediction\"], df[\"id_prediction_distances\"] = predictions.apply(lambda x: x[0]), predictions.apply(lambda x: x[1])\n",
    "    group_predictions = df[:subset_length].progress_apply(lambda x: get_nearest_neighbors(x[\"rental_history_group_embedding\"], nearest_neighbors, NUM_ITEMS, index_to_group_dict), axis=1)\n",
    "    df[\"group_prediction\"], df[\"group_prediction_distances\"] = group_predictions.apply(lambda x: x[0]), group_predictions.apply(lambda x: x[1])\n",
    "    \n",
    "    return df\n",
    "\n",
    "tqdm.pandas()\n",
    "user_splits_df = predict_nearest_neighbors(user_splits_df, outfits_df, subset_length=-1)\n",
    "user_splits_unique_df = predict_nearest_neighbors(user_splits_unique_df, outfits_df, subset_length=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "NUM_ITEMS = 100\n",
    "\n",
    "def find_rental_history_embeddings(outfit_ids, outfit_to_embedding_dict):\n",
    "    return [outfit_to_embedding_dict[outfit_id] for outfit_id in outfit_ids]\n",
    "\n",
    "def get_mean_embedding(embeddings):\n",
    "    embeddings = np.array(embeddings)\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "def get_nearest_neighbors_batch(embeddings, nn, num_items, index_to_id):\n",
    "    distances, indices = nn.kneighbors(embeddings, n_neighbors=num_items+1)\n",
    "    ids = [[index_to_id[i] for i in idx[1:]] for idx in indices]\n",
    "    distances = [dist[1:] for dist in distances]\n",
    "    return ids, distances\n",
    "\n",
    "def predict_nearest_neighbors(df, outfits_df, subset_length=-1):\n",
    "    # Calculate mean embeddings for outfits\n",
    "    outfits_df[\"mean_embeddings\"] = outfits_df[\"embeddings\"].apply(lambda x: get_mean_embedding(x))\n",
    "    outfit_to_embedding_dict = outfits_df.set_index(\"id\")[\"mean_embeddings\"].to_dict()\n",
    "    index_to_outfit_dict = {i: outfit_id for i, outfit_id in enumerate(outfits_df[\"id\"].values)}\n",
    "    group_to_embedding_dict = outfits_df.set_index(\"group\")[\"mean_embeddings\"].to_dict()\n",
    "    index_to_group_dict = {i: group for i, group in enumerate(outfits_df[\"group\"].values)}\n",
    "\n",
    "    # Calculate embeddings for user's rental history\n",
    "    df[\"train_id_embeddings\"] = df[\"train_outfit_ids\"].apply(lambda x: find_rental_history_embeddings(x, outfit_to_embedding_dict))\n",
    "    df[\"train_group_embeddings\"] = df[\"train_group\"].apply(lambda x: find_rental_history_embeddings(x, group_to_embedding_dict))\n",
    "\n",
    "    df[\"rental_history_id_embedding\"] = df[\"train_id_embeddings\"].apply(lambda x: get_mean_embedding(x))\n",
    "    df[\"rental_history_group_embedding\"] = df[\"train_group_embeddings\"].apply(lambda x: get_mean_embedding(x))\n",
    "\n",
    "    # Prepare nearest neighbor model\n",
    "    nearest_neighbors = NearestNeighbors(n_neighbors=NUM_ITEMS+1, metric=\"cosine\")\n",
    "    embeddings = np.stack(outfits_df[\"mean_embeddings\"].values)\n",
    "    nearest_neighbors.fit(embeddings)\n",
    "\n",
    "    # Get embeddings from dataframe\n",
    "    id_embeddings = np.stack(df[\"rental_history_id_embedding\"].values)\n",
    "    group_embeddings = np.stack(df[\"rental_history_group_embedding\"].values)\n",
    "\n",
    "    # Get nearest neighbors for all embeddings in one batch\n",
    "    id_predictions, id_distances = get_nearest_neighbors_batch(id_embeddings, nearest_neighbors, NUM_ITEMS, index_to_outfit_dict)\n",
    "    group_predictions, group_distances = get_nearest_neighbors_batch(group_embeddings, nearest_neighbors, NUM_ITEMS, index_to_group_dict)\n",
    "\n",
    "    # Update dataframe\n",
    "    df[\"id_prediction\"], df[\"id_prediction_distances\"] = id_predictions, id_distances\n",
    "    df[\"group_prediction\"], df[\"group_prediction_distances\"] = group_predictions, group_distances\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply to dataframes\n",
    "tqdm.pandas()\n",
    "user_splits_df = predict_nearest_neighbors(user_splits_df, outfits_df, subset_length=-1)\n",
    "user_splits_unique_df = predict_nearest_neighbors(user_splits_unique_df, outfits_df, subset_length=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_tsne = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Plot the t-SNE result\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], s=5, cmap='viridis')\n",
    "plt.title('t-SNE of Embeddings')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if test outfit is in train outfits for recommendation of repeated outfits\n",
    "# def check_if_test_in_train(train_outfit_ids, test_outfit_id):\n",
    "#     return test_outfit_id in train_outfit_ids\n",
    "\n",
    "# user_splits_df[\"test_in_train\"] = user_splits_df.apply(lambda x: check_if_test_in_train(x[\"train_outfit_ids\"], x[\"test_outfit_id\"]), axis=1)\n",
    "# user_splits_unique_df[\"test_in_train\"] = user_splits_unique_df.apply(lambda x: check_if_test_in_train(x[\"train_outfit_ids\"], x[\"test_outfit_id\"]), axis=1)\n",
    "# display(user_splits_df[\"test_in_train\"].value_counts())\n",
    "# user_splits_df[[\"train_outfit_ids\", \"test_outfit_id\", \"id_prediction\", \"test_in_train\"]]\n",
    "# display(user_splits_unique_df[\"test_in_train\"].value_counts())\n",
    "# user_splits_unique_df[[\"train_outfit_ids\", \"test_outfit_id\", \"id_prediction\", \"test_in_train\"]]\n",
    "\n",
    "\n",
    "# user_splits_unique_df[\"train_length\"] = user_splits_unique_df[\"train_outfit_ids\"].apply(len)\n",
    "# user_splits_unique_df[\"prediction_length\"] = user_splits_unique_df[\"id_prediction\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.043321\n",
       "id_hit_rate_at_10        0.009477\n",
       "group_hit_rate_at_100    0.047383\n",
       "group_hit_rate_at_10     0.012184\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.044695\n",
       "id_hit_rate_at_10        0.007223\n",
       "group_hit_rate_at_100    0.047856\n",
       "group_hit_rate_at_10     0.009481\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def evaluate_hit_rate_at_n(test_id, predicted_ids, n=10):\n",
    "    if predicted_ids is np.nan:\n",
    "        print(f\"None prediction for {test_id}!\")\n",
    "        return 0\n",
    "    predicted_ids = predicted_ids[:n]\n",
    "    if test_id in predicted_ids:\n",
    "        #print(f\"Hit at {n} for {test_id} in {predicted_ids}\")\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "HIT_RATE_COLUMNS = [\"id_hit_rate_at_100\", \"id_hit_rate_at_10\", \"group_hit_rate_at_100\", \"group_hit_rate_at_10\"]\n",
    "def evaluate_df_hit_rate_at_n(df, n=10):\n",
    "    df[\"id_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"id_prediction\"], n=100), axis=1)\n",
    "    df[\"id_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"id_prediction\"], n=10), axis=1)\n",
    "    df[\"group_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_prediction\"], n=100), axis=1)\n",
    "    df[\"group_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_prediction\"], n=10), axis=1)\n",
    "    display(df[HIT_RATE_COLUMNS].mean())\n",
    "    return df\n",
    "\n",
    "\n",
    "user_splits_df = evaluate_df_hit_rate_at_n(user_splits_df, n=10)\n",
    "user_splits_unique_df = evaluate_df_hit_rate_at_n(user_splits_unique_df, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Embeddings Ind: & 0.0095 & 0.0433 & 0.0072 & 0.0447 \\\\\n",
      "Image Embeddings Groups: & 0.0122 & 0.0474 & 0.0095 & 0.0479 \\\\\\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyperclip\n",
    "\n",
    "def format_dicts_into_latex(all_dict, ind_dict, precision=4, run_name=\"Random\"):\n",
    "    first_row = f\"{run_name} Ind: & {all_dict['id_hit_rate_at_10']:.{precision}f} & {all_dict['id_hit_rate_at_100']:.{precision}f} & {ind_dict['id_hit_rate_at_10']:.{precision}f} & {ind_dict['id_hit_rate_at_100']:.{precision}f} \\\\\\\\\"\n",
    "    second_row = f\"{run_name} Groups: & {all_dict['group_hit_rate_at_10']:.{precision}f} & {all_dict['group_hit_rate_at_100']:.{precision}f} & {ind_dict['group_hit_rate_at_10']:.{precision}f} & {ind_dict['group_hit_rate_at_100']:.{precision}f} \\\\\\\\\\\\hline\"\n",
    "    full_string = first_row + \"\\n\" + second_row + \"\\n\"\n",
    "    print(full_string)\n",
    "    pyperclip.copy(full_string)\n",
    "\n",
    "all_dict = {column: user_splits_df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "ind_dict = {column: user_splits_unique_df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "\n",
    "format_dicts_into_latex(all_dict, ind_dict, precision=4, run_name=\"Image Embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_outfit_category(tag_categories, tags, category):\n",
    "    tag_categories, tags = np.array(tag_categories), np.array(tags)\n",
    "    category_indexes = np.where(tag_categories == category)[0]\n",
    "    if len(category_indexes) == 0:\n",
    "        return \"\"\n",
    "    cat_tags = tags[category_indexes]\n",
    "    output = str(cat_tags[0])\n",
    "    return output\n",
    "\n",
    "outfits_df[\"size\"] = outfits_df.apply(lambda x: get_outfit_category(x[\"tag_categories\"], x[\"outfit_tags\"], \"Size\"), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>group</th>\n",
       "      <th>owner</th>\n",
       "      <th>timeCreated</th>\n",
       "      <th>retailPrice</th>\n",
       "      <th>outfit_tags</th>\n",
       "      <th>tag_categories</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outfit.fffdaa715c3646f8b1c0f04d549ff07e</td>\n",
       "      <td>Out of stock - Asymmetric Frilled Dress</td>\n",
       "      <td>This fun, short dress features and asymmetric ...</td>\n",
       "      <td>group.50a586c78eb7626e294ba3bd07d12c79</td>\n",
       "      <td>464</td>\n",
       "      <td>2017-12-30 11:28:01.000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>[Metallic, Synthetic, Cotton, Sandro, Dresses,...</td>\n",
       "      <td>[Details, Material, Material, Brand, Category,...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outfit.fffa1b9a3db6415d806f3c48f8ab58d9</td>\n",
       "      <td>Yellow Shell Mellomholmene Blouse</td>\n",
       "      <td>This beautiful blouse features an adjustable n...</td>\n",
       "      <td>group.61ad2fcabb3e9197e3836376e6b67f2c</td>\n",
       "      <td>112</td>\n",
       "      <td>2021-06-07 12:07:22.921</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>[Yellow, Cotton, Blouses, Everyday, M, Summer,...</td>\n",
       "      <td>[Color, Material, Category, Occasion, Size, Se...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outfit.fff175b13ceb453f9928625491412ede</td>\n",
       "      <td>Kaula Dress Black</td>\n",
       "      <td>Kaula from Rodebjer is a fitted dress made in ...</td>\n",
       "      <td>group.37c2b59d63d3a9c2d58e07f532f71f7f</td>\n",
       "      <td>635</td>\n",
       "      <td>2023-06-05 09:17:59.004</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>[Synthetic, Multi Season, Rodebjer, Everyday, ...</td>\n",
       "      <td>[Material, Seasons, Brand, Occasion, Size, Cat...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outfit.ffef9d7c292a48b69076d2df2e32352f</td>\n",
       "      <td>For sale - Jarvis Blouse</td>\n",
       "      <td>This wrap blouse has mid length sleeves and a ...</td>\n",
       "      <td>group.dfcaa57546b0b7a5e9eb204449b6cc1c</td>\n",
       "      <td>745</td>\n",
       "      <td>2021-05-18 14:02:28.690</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>[Cotton, Multi Season, Floral, Wrap, XS, Style...</td>\n",
       "      <td>[Material, Seasons, Details, Fit, Size, Brand,...</td>\n",
       "      <td>XS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outfit.ffeef842238f4dbdabc6c730a75aa2bd</td>\n",
       "      <td>Black Amber Pants</td>\n",
       "      <td>Feel slack and nice dressed with this pant, ma...</td>\n",
       "      <td>group.ee297c977905eb21a123a4aea5fbb6d2</td>\n",
       "      <td>504</td>\n",
       "      <td>2021-07-16 14:02:30.643</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>[Winter, Cotton, L, Knitwear, Everyday, Fall, ...</td>\n",
       "      <td>[Seasons, Material, Size, Category, Occasion, ...</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15824</th>\n",
       "      <td>outfit.001bf665330140cf854dcfb1cbff6b5f</td>\n",
       "      <td>Out of stock - Harley Vintage White Midi Dress</td>\n",
       "      <td>This gorgeous dress is cut in the most flatter...</td>\n",
       "      <td>group.d91a2a6728833c8082dadf27b95488a9</td>\n",
       "      <td>140</td>\n",
       "      <td>2019-06-25 10:13:55.000</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>[Viscose, L, Midi, Dresses, White, Formal, Pia...</td>\n",
       "      <td>[Material, Size, Length, Category, Color, Occa...</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15825</th>\n",
       "      <td>outfit.0018701ce6b049ebadc314d16623caa8</td>\n",
       "      <td>Vintage Burberry Trench Coat</td>\n",
       "      <td>You really can't go wrong with this Classic Tr...</td>\n",
       "      <td>group.6be510229d0f9faf5d19d52e7e2b2a95</td>\n",
       "      <td>58</td>\n",
       "      <td>2023-02-07 07:54:06.214</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>[Winter, Cotton, Midi, Everyday, Fall, Burberr...</td>\n",
       "      <td>[Seasons, Material, Length, Occasion, Seasons,...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15826</th>\n",
       "      <td>outfit.0014a5c89b244077a3d7cffd4549718e</td>\n",
       "      <td>Mira Skirt Brown</td>\n",
       "      <td>The Mira Skirt in Brown from Stine Goya is an ...</td>\n",
       "      <td>group.668be5db7976aa2cb9213dd4c7f9b7fe</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-10-09 09:12:14.631</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>[Viscose, Midi, Skirts, Summer, Stine Goya, Ev...</td>\n",
       "      <td>[Material, Length, Category, Seasons, Brand, B...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15827</th>\n",
       "      <td>outfit.0013691ff35b440e9dcfe1748ec184c7</td>\n",
       "      <td>Oldina Parka Cotta</td>\n",
       "      <td>The Oldina Parka from Kari Traa is a women's p...</td>\n",
       "      <td>group.c82046bcba672c8ec9b21be4f844b402</td>\n",
       "      <td>552</td>\n",
       "      <td>2023-02-23 12:20:27.042</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>[Winter, Synthetic, Midi, Everyday, XS, Coats,...</td>\n",
       "      <td>[Seasons, Material, Length, Occasion, Size, Ca...</td>\n",
       "      <td>XS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15828</th>\n",
       "      <td>outfit.00004b4d01ca4ab0a70cf073ba74fefa</td>\n",
       "      <td>Yugen Black Cardigan</td>\n",
       "      <td>The FWSS Yugen Cardigan is a form-fitted cardi...</td>\n",
       "      <td>group.4002da292009a8bb0d403bbaf734184e</td>\n",
       "      <td>592</td>\n",
       "      <td>2022-03-01 10:58:12.456</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>[Wool, Winter, Everyday, Fall, M, Cardigans, B...</td>\n",
       "      <td>[Material, Seasons, Occasion, Seasons, Size, C...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15829 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            id  \\\n",
       "0      outfit.fffdaa715c3646f8b1c0f04d549ff07e   \n",
       "1      outfit.fffa1b9a3db6415d806f3c48f8ab58d9   \n",
       "2      outfit.fff175b13ceb453f9928625491412ede   \n",
       "3      outfit.ffef9d7c292a48b69076d2df2e32352f   \n",
       "4      outfit.ffeef842238f4dbdabc6c730a75aa2bd   \n",
       "...                                        ...   \n",
       "15824  outfit.001bf665330140cf854dcfb1cbff6b5f   \n",
       "15825  outfit.0018701ce6b049ebadc314d16623caa8   \n",
       "15826  outfit.0014a5c89b244077a3d7cffd4549718e   \n",
       "15827  outfit.0013691ff35b440e9dcfe1748ec184c7   \n",
       "15828  outfit.00004b4d01ca4ab0a70cf073ba74fefa   \n",
       "\n",
       "                                                 name  \\\n",
       "0             Out of stock - Asymmetric Frilled Dress   \n",
       "1                   Yellow Shell Mellomholmene Blouse   \n",
       "2                                   Kaula Dress Black   \n",
       "3                            For sale - Jarvis Blouse   \n",
       "4                                   Black Amber Pants   \n",
       "...                                               ...   \n",
       "15824  Out of stock - Harley Vintage White Midi Dress   \n",
       "15825                    Vintage Burberry Trench Coat   \n",
       "15826                                Mira Skirt Brown   \n",
       "15827                             Oldina Parka Cotta    \n",
       "15828                            Yugen Black Cardigan   \n",
       "\n",
       "                                             description  \\\n",
       "0      This fun, short dress features and asymmetric ...   \n",
       "1      This beautiful blouse features an adjustable n...   \n",
       "2      Kaula from Rodebjer is a fitted dress made in ...   \n",
       "3      This wrap blouse has mid length sleeves and a ...   \n",
       "4      Feel slack and nice dressed with this pant, ma...   \n",
       "...                                                  ...   \n",
       "15824  This gorgeous dress is cut in the most flatter...   \n",
       "15825  You really can't go wrong with this Classic Tr...   \n",
       "15826  The Mira Skirt in Brown from Stine Goya is an ...   \n",
       "15827  The Oldina Parka from Kari Traa is a women's p...   \n",
       "15828  The FWSS Yugen Cardigan is a form-fitted cardi...   \n",
       "\n",
       "                                        group  owner              timeCreated  \\\n",
       "0      group.50a586c78eb7626e294ba3bd07d12c79    464  2017-12-30 11:28:01.000   \n",
       "1      group.61ad2fcabb3e9197e3836376e6b67f2c    112  2021-06-07 12:07:22.921   \n",
       "2      group.37c2b59d63d3a9c2d58e07f532f71f7f    635  2023-06-05 09:17:59.004   \n",
       "3      group.dfcaa57546b0b7a5e9eb204449b6cc1c    745  2021-05-18 14:02:28.690   \n",
       "4      group.ee297c977905eb21a123a4aea5fbb6d2    504  2021-07-16 14:02:30.643   \n",
       "...                                       ...    ...                      ...   \n",
       "15824  group.d91a2a6728833c8082dadf27b95488a9    140  2019-06-25 10:13:55.000   \n",
       "15825  group.6be510229d0f9faf5d19d52e7e2b2a95     58  2023-02-07 07:54:06.214   \n",
       "15826  group.668be5db7976aa2cb9213dd4c7f9b7fe      4  2023-10-09 09:12:14.631   \n",
       "15827  group.c82046bcba672c8ec9b21be4f844b402    552  2023-02-23 12:20:27.042   \n",
       "15828  group.4002da292009a8bb0d403bbaf734184e    592  2022-03-01 10:58:12.456   \n",
       "\n",
       "       retailPrice                                        outfit_tags  \\\n",
       "0           4000.0  [Metallic, Synthetic, Cotton, Sandro, Dresses,...   \n",
       "1           1300.0  [Yellow, Cotton, Blouses, Everyday, M, Summer,...   \n",
       "2           3100.0  [Synthetic, Multi Season, Rodebjer, Everyday, ...   \n",
       "3           1500.0  [Cotton, Multi Season, Floral, Wrap, XS, Style...   \n",
       "4           1200.0  [Winter, Cotton, L, Knitwear, Everyday, Fall, ...   \n",
       "...            ...                                                ...   \n",
       "15824       3800.0  [Viscose, L, Midi, Dresses, White, Formal, Pia...   \n",
       "15825      22000.0  [Winter, Cotton, Midi, Everyday, Fall, Burberr...   \n",
       "15826       1500.0  [Viscose, Midi, Skirts, Summer, Stine Goya, Ev...   \n",
       "15827       3500.0  [Winter, Synthetic, Midi, Everyday, XS, Coats,...   \n",
       "15828       1900.0  [Wool, Winter, Everyday, Fall, M, Cardigans, B...   \n",
       "\n",
       "                                          tag_categories size  \n",
       "0      [Details, Material, Material, Brand, Category,...    S  \n",
       "1      [Color, Material, Category, Occasion, Size, Se...    M  \n",
       "2      [Material, Seasons, Brand, Occasion, Size, Cat...    M  \n",
       "3      [Material, Seasons, Details, Fit, Size, Brand,...   XS  \n",
       "4      [Seasons, Material, Size, Category, Occasion, ...    L  \n",
       "...                                                  ...  ...  \n",
       "15824  [Material, Size, Length, Category, Color, Occa...    L  \n",
       "15825  [Seasons, Material, Length, Occasion, Seasons,...    S  \n",
       "15826  [Material, Length, Category, Seasons, Brand, B...    S  \n",
       "15827  [Seasons, Material, Length, Occasion, Size, Ca...   XS  \n",
       "15828  [Material, Seasons, Occasion, Seasons, Size, C...    M  \n",
       "\n",
       "[15829 rows x 10 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfits_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
